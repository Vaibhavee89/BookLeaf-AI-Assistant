version: '3.8'

services:
  # Backend FastAPI Service
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: bookleaf-backend
    ports:
      - "8000:8000"
    environment:
      # Application Settings
      - APP_NAME=BookLeaf AI Assistant
      - APP_VERSION=1.0.0
      - ENVIRONMENT=development
      - DEBUG=true
      - LOG_LEVEL=INFO

      # API Settings
      - API_V1_PREFIX=/api/v1
      - CORS_ORIGINS=["http://localhost:3000","http://frontend:3000"]

      # OpenAI Configuration (REQUIRED)
      - OPENAI_API_KEY=${OPENAI_API_KEY}

      # Supabase Configuration (REQUIRED)
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_KEY=${SUPABASE_KEY}
      - SUPABASE_SERVICE_ROLE_KEY=${SUPABASE_SERVICE_ROLE_KEY}

      # LLM Configuration
      - PRIMARY_MODEL=gpt-4-turbo-preview
      - FALLBACK_MODEL=gpt-4
      - CLASSIFICATION_MODEL=gpt-4o-mini
      - EMBEDDING_MODEL=text-embedding-3-large
      - EMBEDDING_DIMENSIONS=1536

      # Confidence Thresholds
      - CONFIDENCE_THRESHOLD_AUTO_RESPOND=0.80
      - CONFIDENCE_THRESHOLD_ESCALATE=0.80

      # RAG Configuration
      - RAG_TOP_K=5
      - RAG_CHUNK_SIZE=500
      - RAG_CHUNK_OVERLAP=50
      - RAG_MAX_CONTEXT_TOKENS=8000

      # Identity Matching Configuration
      - FUZZY_MATCH_THRESHOLD=85
      - IDENTITY_CONFIDENCE_WEIGHT=0.30
      - INTENT_CONFIDENCE_WEIGHT=0.20
      - RAG_CONFIDENCE_WEIGHT=0.25
      - LLM_CONFIDENCE_WEIGHT=0.25

      # Rate Limiting
      - MAX_RETRIES=3
      - RETRY_DELAY=1.0
      - REQUEST_TIMEOUT=30.0
    volumes:
      - ./backend:/app
      - ./data:/data
      - ./knowledge-base:/knowledge-base
      - /app/venv  # Prevent overwriting container's venv
    networks:
      - bookleaf-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Frontend Next.js Service
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: bookleaf-frontend
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8000
      - NEXT_PUBLIC_APP_NAME=BookLeaf AI Assistant
      - NODE_ENV=production
    depends_on:
      - backend
    networks:
      - bookleaf-network
    restart: unless-stopped

networks:
  bookleaf-network:
    driver: bridge

volumes:
  backend-data:
